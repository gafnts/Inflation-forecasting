---
bibliography: references.bib
---

# Resultados

```{r include=FALSE}
pacman::p_load(tidyverse, kableExtra, magrittr, here, patchwork, ggforce)
main <- read_csv(here("data", "main.csv")) %>% select(fecha, ipc) %>% rowid_to_column(".row")
```

Esta investigación compara la precisión en los pronósticos durante 4 horizontes temporales entre métodos econométricos comúnmente utilizados y diversas alternativas basadas en modelos de aprendizaje estadístico. El cuadro 4 muestra los resultados obtenidos por modelo y horizonte de pronóstico en términos del error absoluto medio (MAE) y el error absoluto medio relativo (rMAE). Como ha sido mencionado con anterioridad, un modelo de caminata aleatoria es empleado como línea base con la que el resto de los métodos son evaluados.

En principio, es posible apreciar que todos los métodos se desempeñan mejor de lo que lo hace el modelo ingenuo de referencia. Sin embargo, ciertamente existe heterogeneidad en cuanto a la forma en la que cada modelo se comporta durante la predicción de la variable objetivo en los distintos intervalos de tiempo.

En lo que respecta a los métodos de series de tiempo, el modelo de caminata aleatoria estacional es comparativamente el más ineficiente en 3 de los 4 horizontes temporales. Además, el modelo de suavizamiento exponencial con estacionalidad aditiva y el modelo autorregresivo de segundo orden mantienen un desempeño similar a lo largo de todos los horizontes, aunque este último es más eficiente en cada uno de ellos (exceptuando a sus pronósticos de 24 meses hacia delante, donde ambos obtienen resultados idénticos en términos del rMAE).

Mientras tanto, el modelo SARIMA y el modelo VAR---cuya especificación utiliza únicamente tres variables: las tasas de variación interanual del IPC y del IMAE, así como la segunda diferencia del medio circulante, cada una de ellas rezagada por 24 periodos---son los métodos que, en general, cuentan con la eficiencia más alta durante los pronósticos de 3 meses hacia delante. El excelente desempeño del modelo SARIMA se extiende hasta el horizonte de 12 periodos.

\vspace{.5mm}

```{=tex}
\begin{center}

\small

\textbf{Cuadro 4:} MAE y rMAE para cada modelo y horizonte de pronóstico

\normalsize

\end{center}
```
\vspace{-2.7mm}

```{r include=FALSE}
mae <- read_csv(here("results", "analysis", "final_mae.csv"))
rmae <- read_csv(here("results", "analysis", "final_rmae.csv")) %>% 
  rename("h = 3 " = 2, "h = 9 " = 3, "h = 12 " = 4, "h = 24 " = 5)

results_one <- 
  mae %>% 
  left_join(rmae) %>% 
  mutate(across(where(is.numeric), ~ round(., 2)),
         key = str_remove_all(key, "[()]")) %>% 
  rename(" " = 1) %>% 
  filter(` ` != "ts & ml ensemble") %>%
  mutate(` ` = str_replace(` `, "svm", "svr"))
```

```{r table_four, echo=FALSE}
kbl(results_one, 
    booktabs = T,
    align = c("lcccccccc")) %>%
  kable_styling(font_size = 9,
                full_width = T) %>% 
  add_header_above(c(" " = 1, "MAE" = 4, "rMAE" = 4), align = "l") %>%
  column_spec(1, width = "2.9cm") %>% 
  group_rows(start_row = 1, 
             end_row = 6, 
             latex_gap_space = "-0.25cm") %>% 
  row_spec(6, bold = TRUE) %>% 
  group_rows(start_row = 7, 
             end_row = 12, 
             latex_gap_space = "-0.10cm") %>% 
  row_spec(12, bold = TRUE)
```

\vspace{5mm}

Por otro lado, los pronósticos de la regresión de vectores de soporte (SVR) superan en todos los horizontes a los de los modelos econométricos más simples y a la mayoría de las predicciones de los algoritmos de aprendizaje de máquina. Sin embargo, lo mismo no ocurre cuando su desempeño es contrastado con el desempeño del modelo SARIMA (al que únicamente supera durante su predicción de 24 meses hacia delante) o con los 2 pronósticos de más corto plazo del modelo VAR.

Si bien los algoritmos de bosques aleatorios (RF) y de potenciación de gradiente extremo (XGB) no son capaces de superar en ningún caso a la eficiencia de los pronósticos de la regresión de vectores de soporte (SVR), sí logran mejores resultados al ser comparados con los modelos econométricos más simples e incluso superan con creces a la eficiencia de los modelos SARIMA y VAR en el horizonte temporal de dos años.

Una situación similar acontece con los modelos de redes neuronales (el perceptrón multicapa y la red neuronal recurrente de larga memoria de corto plazo, la cual, a diferencia del resto de modelos de aprendizaje estadístico en este estudio, utiliza como predictor únicamente el ritmo inflacionario rezagado por 35 periodos).

Sin embargo, en promedio, el perceptrón multicapa es ligeramente más eficiente que el algoritmo de potenciación de gradiente extremo mientras que, dentro de la categoría de *machine learning*, la red neuronal de larga memoria de corto plazo cuenta con el peor desempeño en términos de error absoluto medio. Si bien ambos modelos superan consistentemente a los métodos econométricos más simples, lo contrario sucede al contrastar sus resultados con los de los modelos SARIMA y VAR (especialmente durante los pronósticos de corto plazo) y con los del resto de modelos de aprendizaje estadístico.

```{=tex}
\begin{center}

\small

\textbf{Figura 2:} Pronósticos de 24 meses hacia delante

\end{center}
```
\vspace{-10mm}

```{r include=FALSE}
ts_forecasts <- read_csv(here("results", "analysis", "ts_24_forecasts.csv"))
ml_forecasts <- read_csv(here("results", "analysis", "ml_24_forecasts.csv")) %>%
  mutate(model = str_replace(model, "svm", "svr"))
```

```{r include=FALSE}
p1 <- 
  ggplot(filter(ts_forecasts, model != "ipc"), aes(fecha, value, color = model)) +
  geom_line(aes(fecha, value, color = model)) +
  geom_line(data = filter(ts_forecasts, model == "ipc"), linetype = "dashed") +
  labs(title = "Modelos de series de tiempo") +
  theme_bw() +
  theme(
        # X axis
        axis.title.x = element_blank(),
        axis.text.x = element_text(size = 12, color = "black"),
        # Y axis
        axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12, color = "black"),
        # Title
        plot.title = element_text(hjust = 0.5, 
                                  margin = margin(0, 0, 0.7, 0, "cm")),
        # Panel
        panel.grid = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_rect(fill = "white", color = "black"),
        # Legend
        legend.title = element_blank(),
        legend.text = element_text(size = 11),
        legend.position = "bottom",
        legend.justification = "center",
        legend.margin = margin(.5, 0, 0, 0, "cm")
    ) + 
    guides(colour = guide_legend(nrow = 1))
```

```{r include=FALSE}
p2 <- 
  ggplot(filter(ml_forecasts, model != "ipc"), aes(fecha, value, color = model)) +
  geom_line(aes(fecha, value, color = model)) +
  geom_line(data = filter(ml_forecasts, model == "ipc"), linetype = "dashed") +
  labs(title = "Modelos de aprendizaje estadístico") +
  theme_bw() +
  theme(
        # X axis
        axis.title.x = element_blank(),
        axis.text.x = element_text(size = 12, color = "black"),
        # Y axis
        axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12, color = "black"),
        # Title
        plot.title = element_text(hjust = 0.5, 
                                  margin = margin(0, 0, 0.7, 0, "cm")),
        # Panel
        panel.grid = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_rect(fill = "white", color = "black"),
        # Legend
        legend.title = element_blank(),
        legend.text = element_text(size = 11),
        legend.position = "bottom",
        legend.justification = "center",
        legend.margin = margin(.5, 0, 0, 0, "cm")
    ) + 
    guides(colour = guide_legend(nrow = 1))
```

```{r fig_two, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center', fig.dim = c(11.5, 4.7)}
p1 + p2
```

El cuadro 4 también presenta los resultados de una combinación de pronósticos por cada método, mientras que la figura 3 muestra las series de tiempo de ambas combinaciones durante la predicción de 24 meses hacia delante. Estos ensambles se realizan a través de una media ponderada en la que el peso relativo de los ponderadores está dado por:

\vspace{-2mm}

$$
w_i = 1 - \frac{MAE_h}{\sum_{h=1}^H MAE},
$$

\vspace{1mm}

donde $MAE_h$ es el error absoluto medio del pronóstico en el periodo $h$ de un modelo específico y $H$ representa al horizonte de predicción. De tal forma, $w_i$ pondera con un mayor peso a las predicciones de los modelos que tienen un menor MAE. Este método de combinación de pronósticos es considerado como una técnica dinámica cuya ventaja principal es abstraer mayor complejidad estadística en comparación con estimar un vector constante de ponderación y aplicarlo durante todo el horizonte de pronóstico [@wang2018].

En uno de los estudios seminales en la literatura de combinación de pronósticos, @bates1969 mencionan que dado a que diferentes métodos utilizan distintos supuestos acerca de la forma en la que las variables se relacionan, combinaciones de los resultados de distintos modelos pueden mejorar la precisión en sus predicciones, aunque no es necesariamente el caso que tal resultado pueda obtenerse siempre. En esta investigación, la combinación de los pronósticos de modelos econométricos genera predicciones más eficientes en el horizonte de 24 meses. Además, el ensamble de pronósticos de modelos de aprendizaje estadístico produce una mejora en la eficiencia para el horizonte de 12 periodos hacia delante y supera en 3 de los 4 horizontes a la combinación de pronósticos de modelos de series de tiempo.

```{=tex}
\begin{center}

\small

\textbf{Figura 3:} Combinación de pronósticos por clase de método

\end{center}
```
\vspace{-10mm}

```{r include=FALSE}
ts_mean_forecasts <- read_csv(here("results", "analysis", "ts_mean_forecasts.csv"))
ml_mean_forecasts <- read_csv(here("results", "analysis", "ml_mean_forecasts.csv"))
ensamble <- ts_mean_forecasts %>% bind_rows(ml_mean_forecasts %>% filter(model != "ipc"))
```

```{r fig_three, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center', fig.dim = c(11.5, 4.7)}
ggplot(filter(ensamble, model != "ipc"), aes(fecha, value, color = model)) +
  geom_line(aes(fecha, value, color = model)) +
  geom_line(data = filter(ensamble, model == "ipc"), linetype = "dashed") +
  theme_bw() +
  theme(
        # X axis
        axis.title.x = element_blank(),
        axis.text.x = element_text(size = 12, color = "black"),
        # Y axis
        axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12, color = "black"),
        # Title
        plot.title = element_blank(),
        # Panel
        panel.grid = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_rect(fill = "white", color = "black"),
        # Legend
        legend.title = element_blank(),
        legend.text = element_text(size = 11),
        legend.position = "bottom",
        legend.justification = "center",
        legend.margin = margin(.5, 0, 0, 0, "cm")
    ) + 
    guides(colour = guide_legend(nrow = 1))
```

Como ha sido mencionado previamente, el error absoluto medio escalado (MASE) contrasta los errores fuera de muestra entre un modelo de caminata aleatoria y el método que se desea evaluar. Si bien, en teoría un MASE menor que uno es la magnitud deseable del error en la predicción de un modelo particular durante el horizonte $H$, en la práctica esto rara vez ocurre, por lo que resulta problemático juzgar la precisión de los pronósticos sin considerar que los modelos pueden desempeñarse de formas diferentes según las características de los datos que se emplean.

Por ejemplo, @athanasopoulos2011, al comparar las predicciones de diversos métodos de suavizamiento exponencial con pronósticos de modelos ARIMA, utilizan como punto de referencia el promedio del MASE en este último modelo durante todos los horizontes temporales en lugar de la unidad. En línea con dicha investigación, el presente estudio utilizará el valor 8.58 (el MASE promedio del modelo de caminata aleatoria estacional durante los cuatro horizontes de pronóstico) como *benchmark* para el resto de modelos. Tanto el cuadro 5 como la figura 4 presentan los resultados obtenidos por cada uno de los métodos al ser evaluados por esta medida de precisión.

La comparación del MASE promedio durante todos los horizontes de pronóstico de los modelos de series de tiempo muestra que cada uno de ellos supera, en términos de eficiencia, al modelo de caminata aleatoria estacional. Además, exceptuando al pronóstico del modelo de suavizamiento exponencial durante el horizonte de 9 meses, la eficiencia en la predicción de cada uno de los periodos individuales se mantiene por debajo del promedio del modelo de referencia.

```{=tex}
\begin{center}

\small

\textbf{Cuadro 5:} MASE por modelo y horizonte de pronóstico

\normalsize

\end{center}
```
\vspace{-3.5mm}

```{r include=FALSE}
mase <- read_csv(here("results", "analysis", "final_mase.csv")) %>% 
  rename(" " = name)

mase_mean <- 
  mase %>% 
  summarise(across(where(is.numeric), mean)) %>% 
  mutate(` ` = "Media") %>% 
  relocate(` `)

mase %<>% 
  bind_rows(mase_mean) %>%
  mutate(across(where(is.numeric), ~ round(., 2))) %>% 
  rename("svr" = svm)
```

```{r table_five, echo=FALSE}
kbl(mase, 
    booktabs = T,
    align = c("lcccccccccc")) %>%
  kable_classic() %>% 
  add_header_above(c(" " = 1, "MASE" = 10), align = "l") %>%
  kable_styling(font_size = 9,
                full_width = T,
                latex_options = "hold_position") %>% 
  column_spec(1, width = "2cm") %>% 
  column_spec(3, width = "1.9cm") %>% 
  group_rows(start_row = 1, 
             end_row = 4, 
             label_row_css = "l",
             latex_gap_space = "-0.25cm") %>% 
  group_rows(start_row = 5, 
             end_row = 5, 
             label_row_css = "l",
             latex_gap_space = "-0.10cm") %>% 
  row_spec(5, bold = TRUE)
```

```{=tex}
\begin{center}

\small

\textbf{Figura 4:} MASE por modelo y horizonte de pronóstico

\end{center}
```
\vspace{-10mm}

```{r include=FALSE}
ranking_mase <- read_csv(here("results", "analysis", "ranking_mase.csv")) %>% 
  mutate(horid = rep(1:4, times = 10),
         key = case_when(
           key == "snaive" ~ "snaïve", 
           TRUE ~ key
         )) %>% 
  mutate(key = str_replace_all(key, "svm", "svr"))
```

```{r fig_four, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center', fig.dim = c(11.5, 3.9)}
ranking_mase %>% 
  ggplot(aes(fct_inorder(key, id), estimate, fill = fct_inorder(horizon, horid))) +
  geom_col(position = "dodge2") +
  scale_fill_discrete(limits = c("h = 3", "h = 9", "h = 12", "h = 24")) + 
  scale_fill_grey() +
  theme_bw() +
  theme(
        # X axis
        axis.title.x = element_blank(),
        axis.text.x = element_text(size = 12, color = "black"),
        # Y axis
        axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12, color = "black"),
        # Title
        plot.title = element_text(hjust = 0.5, 
                                  margin = margin(0, 0, 0.7, 0, "cm")),
        # Panel
        panel.grid = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_rect(fill = "white", color = "black"),
        # Legend
        legend.title = element_blank(),
        legend.text = element_text(size = 11),
        legend.position = "bottom",
        legend.justification = "center",
        legend.spacing.x = unit(.5, "cm"),
        legend.margin = margin(.3, 0, 0, 0, "cm")
    ) + 
    guides(colour = guide_legend(nrow = 1))
```

SARIMA vuelve a desempeñarse mejor que el resto de métodos estadísticos, llegando incluso durante el horizonte de 9 meses a superar al pronóstico del modelo ingenuo fuera de muestra (lo que lo convierte en el único método de series de tiempo que consigue obtener un MASE menor que la unidad para algún horizonte de predicción). El modelo VAR logra resultados comparables, aunque aún lejanos a los del modelo SARIMA.

Mientras tanto, al considerar el desempeño de los diferentes métodos de aprendizaje de máquina, la regresión de vectores de soporte vuelve a superar al resto de modelos, consiguiendo un MASE menor que uno durante el intervalo de predicción de dos años. Los resultados del resto de los métodos son muy similares a los de los resultados evaluados a través del error absoluto medio. Sin embargo, mientras el error absoluto medio cataloga al promedio de las predicciones del perceptrón multicapa como pronósticos más eficientes que los de la red neuronal de larga memoria de corto plazo durante todos los horizontes de pronóstico, ocurre exactamente lo contrario al comparar sus resultados por medio del error medio absoluto escalado.

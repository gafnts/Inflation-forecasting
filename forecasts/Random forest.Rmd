# Random forest

```{r}
pacman::p_load(tidyverse, tidymodels, modeltime, timetk, 
               randomForest, lubridate, magrittr, here, vip)
```

```{r}
data <- read_csv(here("data", "main.csv")) %>% rename("date" = fecha)
```

### Train and test sets

```{r}
splits <- data %>% time_series_split(date, assess = "24 months", cumulative = TRUE)
train <- training(splits)
test <- testing(splits)
```

### Model specification

```{r}
rf <- 
  rand_forest(trees = 1000, min_n = tune(), mtry = tune()) %>% 
  set_engine("randomForest") %>% 
  set_mode("regression")
```

### Feature engineering

```{r}
recipe <- 
  recipe(ipc ~ ., data = train) %>% 
  step_rm(date) # %>% 
  #step_lag(all_predictors(), lag = 1:24) %>% 
  #step_naomit(all_predictors())
```

```{r}
recipe %>% prep() %>% juice()
```

### Workflow

```{r}
workflow <- 
  workflow() %>% 
  add_model(rf) %>% 
  add_recipe(recipe)
```

### Hyperparameter tuning

```{r}
resamples <- 
  train %>% 
  rolling_origin(
    initial = 8 * 12,
    assess = 2 * 12,
    skip = 10,
    cumulative = TRUE)
```

```{r}
resamples %>%
  tk_time_series_cv_plan() %>%
  plot_time_series_cv_plan(date, ipc, 
                           .facet_ncol = 2, .interactive = F)
```

```{r}
grid <- 
  grid_latin_hypercube(
  min_n(),
  finalize(mtry(), train),
  size = 15
)
```

```{r}
doParallel::registerDoParallel()

metrics <- metric_set(mae, mase)

set.seed(123)
tune <- tune_grid(
  workflow,
  resamples = resamples,
  grid = grid,
  metrics = metrics,
  control = control_grid(save_pred = TRUE)
)
```

```{r}
tune %>% collect_metrics() %>% print(n = Inf)
best_mae <- select_best(tune, "mae"); best_mae
```

```{r}
tune %>%
  collect_metrics() %>%
  filter(.metric == "mae") %>%
  select(mean, mtry:min_n) %>%
  pivot_longer(mtry:min_n,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "MAE")
```

### Final model

```{r}
final <- 
  finalize_workflow(
  workflow,
  best_mae
)
```

```{r}
final %>%
  fit(data = train) %>%
  extract_fit_parsnip() %>%
  vip(geom = "col")
```

```{r}
final_res <- last_fit(final, splits, metrics = metrics)
collect_metrics(final_res)
```

### Forecast

```{r}
final_res %>%
  collect_predictions() %>% 
  select(.pred, .row, ipc) %>% 
  pivot_longer(-.row) %>% 
  ggplot(aes(.row, value, color = name)) +
  geom_line()
```

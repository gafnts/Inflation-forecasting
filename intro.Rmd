---
bibliography: references.bib
---

# Introducción

El artículo número tres de la ley orgánica del Banco de Guatemala establece que su objetivo fundamental consiste en propiciar las condiciones monetarias, cambiarias y crediticias que promuevan la estabilidad en el nivel general de precios. En el 2005, como parte de su esfuerzo por lograr este fin, dicha entidad optó por conducir sus acciones a través de un marco de metas de inflación.

Dado a que naturalmente existe un periodo de tiempo entre el ajuste de las condiciones monetarias y el efecto que este cambio genera en las variables reales del sistema macroeconómico, la autoridad monetaria---bajo un régimen de metas explícitas de inflación---actúa en el presente considerando sus pronósticos sobre el comportamiento de los precios en el futuro.

Concretamente, un cambio en la tasa de interés de política monetaria puede demorar entre 12 y 24 meses en ejercer una influencia en la demanda agregada y, por tanto, en tener un impacto en la evolución del ritmo inflacionario interno. En consecuencia, el banco central deberá pronosticar esta variable durante dicho horizonte temporal y efectuar sus decisiones de política monetaria de modo que pueda estar seguro de que los pronósticos y expectativas de inflación se mantendrán anclados a la meta establecida durante el mediano plazo [@moenjak2014a].

En este sentido, los pronósticos de variables macroeconómicas pueden llevarse a cabo a través de dos enfoques distintos: Métodos estructurales y métodos no estructurales [@diebold1998]. Los primeros informan a la especificación de sus modelos a través de una teoría económica específica, mientras que los últimos se valen de las correlaciones en forma reducida que subyacen en las series de tiempo, sin depender explícitamente de una teoría económica [@pratap2019].

Este estudio en particular se ocupará del segundo enfoque, que al mismo tiempo puede ser subdividido en dos metodologías diferentes. Por un lado se encuentran los métodos econométricos de series de tiempo (que pueden considerarse como modelos relativamente tradicionales) entre los que sobresalen los modelos univariados autorregresivos integrados de medias móviles (ARIMA) y los modelos multivariados de vectores autorregresivos (VAR).

Por el otro, algoritmos de aprendizaje estadístico[^1] (*machine learning*) comienzan a ser cada vez más populares, principalmente por la creciente disponibilidad de grandes bases de datos y poder de cómputo, así como un mayor acceso a *software* especializado [@rodríguez-vargas2020], aunque---tal y como mencionan @coulombe2020---los métodos de aprendizaje de máquina en realidad tienen una historia dentro de la literatura macroeconométrica que se remonta hacia inicios de la década de los noventas.

[^1]: A lo largo de la presente investigación los términos "aprendizaje estadístico", "aprendizaje de máquina" y "aprendizaje automático" serán empleados indistintamente.

En general, los modelos de series de tiempo asumen que las variables empleadas durante la estimación de los parámetros se vinculan entre sí a través de una dinámica intrínseca regida por relaciones lineales que únicamente conducen a soluciones que oscilan periódicamente o que exhiben un comportamiento exponencial, de modo que la totalidad en la conducta irregular del sistema es atribuida únicamente a una entrada que es tanto exógena como estocástica [@kantz2004nonlinear].

Sin embargo, esta entrada aleatoria puede no ser la fuente exclusiva de irregularidad. Evidencia apunta que tanto series macroeconómicas como datos financieros exhiben interesantes estructuras no-lineales que se originan debido al impacto de perturbaciones durante las distintas fases del ciclo económico [@granger1993modeling; @lebaron1994].

Dada la naturaleza no-lineal entre la relación de las variables macroeconómicas, existe cada vez un mayor énfasis en la aplicación de modelos de aprendizaje automático, los cuales (a diferencia de sus contrapartes) son particularmente buenos para explotar las relaciones no-lineales e interacciones de alto orden durante el proceso de predicción de nuevos valores basados en los valores de sus regresores [@athey2019]. Precisamente, tal es el propósito del presente estudio.

Por medio de una competencia de predicciones fuera de muestra (*pseudo* *out-of-sample*) entre una amplia gama de modelos que difieren respecto de ciertas características esenciales, esta investigación buscará arrojar luz sobre si modelos de aprendizaje estadístico tales como bosques aleatorios (*random forest*), k vecinos más cercanos (KNN), máquinas de vectores de soporte (SVM), redes neuronales de una sola capa (*single-layer perceptron*) y redes neuronales recurrentes de larga memoria de corto plazo (LSTM) son capaces de generar pronósticos más eficientes en distintos horizontes temporales---comparados a través de tres criterios de evaluación (RMSE, WAPE y MAE)---al contrastarlos con los pronósticos de un repertorio de modelos estimados a partir de métodos econométricos tradicionales.

El resto del documento será organizado de la siguiente manera. La sección 2 hace un repaso de la literatura sobre pronósticos de inflación para economías emergentes y avanzadas. La sección 3 se ocupa de establecer un marco teórico con el objeto de definir formalmente los métodos econométricos y computacionales que serán empleados durante la sección 4. Por último, la sección 5 y 6 se enfocan en discutir los resultados y conclusiones del estudio, respectivamente.

---
bibliography: references.bib
---

# Datos y metodología

## Análisis de datos

Con el objeto de pronosticar la tasa de variación interanual del índice de precios al consumidor en Guatemala, la especificación de los regresores ha sido propuesta a partir de un procedimiento en el que a 36 series de tiempo---escogidas considerando el canal de demanda agregada, el canal de tipo de cambio y las variables del sector externo del mecanismo de transmisión de política monetaria [@castillo2014]---les son aplicadas pruebas de causalidad de Wiener-Granger respecto a la variable objetivo para cada uno de los rezagos de mediano plazo y en el que, posteriormente, son filtradas tomando en cuenta (a) la cantidad de retardos que causan (en el sentido de Granger) al ritmo inflacionario de la economía y (b) la magnitud en el nivel de significancia del estadístico $F$ de los *tests* previamente mencionados.

El cuadro 1 muestra a las 13 variables cuyos valores pasados son los más útiles, dado el conjunto inicial de posibles predictores, para pronosticar los valores futuros de la variación en el nivel de precios de la economía. Los datos corresponden al periodo que abarca de enero del 2005 a diciembre del año 2021.

```{=tex}
\begin{center}

\small

\textbf{Cuadro 1:} Variables empleadas durante el proceso de predicción

\normalsize

\end{center}
```
\vspace{-3mm}

```{r include=FALSE}
pacman::p_load(tidyverse, kableExtra, here, e1071, stats, tseries, pracma, broom)
main <- read_csv(here("data", "main.csv"))
```

```{r include=FALSE}
table_one <- 
  tribble(
  ~ Variable, ~ Descripción, ~ Fuente,
  "ipc", "Tasa de variación interanual del índice de precios al consumidor", "SECMCA",
  "tpm", "Tasa de interés de política monetaria", "SECMCA",
  "m0", "Tasa de variación interanual de la base monetaria restringida", "SECMCA",
  "m1", "Tasa de variación interanual del medio circulante", "SECMCA",
  "imae", "Tasa de variación interanual del índice mensual de actividad económica", "SECMCA",
  "rev", "Tasa de variación interanual de los ingresos totales del gobierno central", "BANGUAT",
  "debt", "Tasa de variación interanual del saldo de la deuda pública externa", "BANGUAT",
  "exports", "Tasa de variación interanual del valor (FOB) de las exportaciones totales", "SECMCA",
  "bananas", "Tasa de variación interanual del valor promedio (dólares por tonelada) de las exportaciones de banano", "SECMCA",
  "hydro", "Tasa de variación interanual del valor promedio (dólares por barril) de las importaciones de hidrocarburos", "SECMCA",
  "lendrate", "Tasa de interés activa (real) en moneda nacional", "SECMCA",
  "deprate", "Tasa de interés pasiva (nominal) en moneda nacional", "SECMCA",
  "itcer", "Tasa de variación interanual del índice de tipo de cambio efectivo real (global)", "SECMCA",
  "cpi", "Tasa de variación interanual del índice de precios al consumidor en Estados Unidos", "FRED"
  )
```

\renewcommand{\arraystretch}{1.35}

```{r table_one, echo=FALSE}
kbl(table_one, 
    booktabs = T, 
    align = c("clc")) %>%
  kable_styling(font_size = 9,
                full_width = T) %>% 
  row_spec(0, align = "c", 
           bold = TRUE, 
           extra_css = 'vertical-align: middle !important;') %>% 
  column_spec(1, width = "1.7cm") %>% 
  column_spec(2, width = "12cm") %>% 
  group_rows(start_row = 1, 
             end_row = 14, 
             latex_align = "c",
             latex_gap_space = "-0.50cm")
```

\renewcommand{\arraystretch}{1}

```{=tex}
\begin{center}

\small

\textbf{Figura 1:} Variable objetivo y predictores seleccionados

\end{center}
```
\vspace{-12mm}

```{r include=FALSE}
order <- table_one %>% rowid_to_column(var = "id") %>% select(id, "name" = Variable)

fig1 <- 
  main %>% 
  pivot_longer(-fecha) %>% 
  arrange(name, fecha) %>% 
  left_join(order) %>% 
  mutate(name = as_factor(name)) %>% 
  group_by(name)
```

```{r fig_one, echo=FALSE, fig.align = 'center', fig.dim = c(11.5, 4.7)}
fig1 %>% 
  ggplot() +
  geom_line(aes(x = fecha, y = value, color = fct_reorder(name, id))) + 
  scale_y_continuous(limits = c(-99, 99)) +
  theme_bw() +
  theme(
        # X axis
        axis.title.x = element_blank(),
        axis.text.x = element_text(size = 12),
        # Y axis
        axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12),
        # Panel
        panel.grid = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_rect(fill = "white"),
        # Legend
        legend.title = element_blank(),
        legend.text = element_text(size = 11),
        legend.position = "bottom",
        legend.justification = "center",
        legend.margin = margin(.5, 0, 0, 0, "cm")
    ) + 
    guides(colour = guide_legend(nrow = 1))
```

\vspace{-2mm}

\normalsize

El cuadro 2 presenta estadísticas descriptivas para cada una de las variables. En ellas se incluyen el primer, tercer y cuarto momentos de sus funciones de densidad de probabilidad (PDF), así como la raíz cuadrada del segundo---para evidenciar la volatilidad de las series. En este último sentido, es posible observar que tanto el cambio interanual en el valor promedio de las importaciones de hidrocarburos, las exportaciones totales y los ingresos del gobierno central son aquellas variables que exhiben una mayor volatilidad durante el periodo del análisis.

Las estadísticas descriptivas también demuestran que esta investigación lidia mayoritariamente con variables que no se distribuyen normalmente, de las cuales 9 presentan distribuciones leptocúrticas, 2 platicúrticas y 3 una distribución aproximadamente normal, en términos de exceso de curtosis. Además, el estadístico de asimetría comprueba que 4 series se encuentran sesgadas hacia la izquierda y el resto de ellas hacia la derecha (exceptuando a la tasa de variación de los ingresos del gobierno central, cuya asimetría es cercana a 0).

```{=tex}
\begin{center}

\small

\textbf{Cuadro 2:} Estadísticas descriptivas

\normalsize

\end{center}
```
\vspace{-4mm}

```{r include=FALSE}
main_longer <- 
  main %>% 
  pivot_longer(-fecha, names_to = "Variable", values_to = "value") %>% 
  arrange(Variable, fecha) %>% 
  group_by(Variable)

sumtable <- 
  main_longer %>% 
  summarise(Media = round(mean(value), 2),
            Mediana = round(median(value), 2),
            Mínimo = round(min(value), 2),
            Máximo = round(max(value), 2),
            `Desv. Est.` = round(sd(value), 2),
            Asimetría = round(skewness(value), 2),
            Curtosis = round(kurtosis(value), 2))

obs <- 
  main_longer %>% 
  count(Variable) %>% 
  rename(`Obs.` = n)

table_two <- 
  sumtable %>% 
  left_join(obs) %>% 
  slice(8, 14, 11, 12, 7, 13, 3, 5, 1, 6, 10, 4, 9, 2) %>% 
  as.data.frame()
```

\renewcommand{\arraystretch}{1.2}

```{r table_two, echo=FALSE}
kbl(table_two, 
    booktabs = T,
    align = c("c")) %>%
  kable_styling(font_size = 9,
                full_width = T) %>% 
  row_spec(0, bold = TRUE) %>% 
  column_spec(1, width = "1.5cm") %>% 
  column_spec(6, width = "1.8cm") %>% 
  column_spec(9, width = "1cm") %>% 
  group_rows(start_row = 1, 
             end_row = 14, 
             latex_align = "c",
             latex_gap_space = "-0.35cm")
```

\renewcommand{\arraystretch}{1}

```{=tex}
\begin{center}

\small

\textbf{Cuadro 3:} Pruebas estadísticas

\normalsize

\end{center}
```
\vspace{-4mm}

```{r include=FALSE}
names <- main_longer %>% distinct(Variable) %>% pull()
```

```{r include=FALSE}
autocorrelation <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    Box.test(., lag = 12, type = "Ljung-Box") %>% 
    tidy()
}

list <- list()
autocor <- data.frame()

for (i in names) {
  list <- autocorrelation(main, all_of(i))
  autocor <- rbind(autocor, list)
}

autocor %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(Autocorrelación = paste(round(statistic, 2), "(0.0000)", sep = " ")) %>% 
  select(Variable, Autocorrelación)
```

```{r include=FALSE}
jarque_bera <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    jarque.bera.test(.) %>% 
    tidy()
}

list <- list()
jarque <- data.frame()

for (i in names) {
  list <- jarque_bera(main, all_of(i))
  jarque <- rbind(jarque, list)
}

jarque %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(p.value = round(p.value, 4)) %>% 
  mutate(Normalidad = paste0(round(statistic, 2), " ", 
                             "(", format(p.value, scientific = FALSE), ")")) %>% 
  select(Variable, Normalidad)
```

```{r include=FALSE}
white_test <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    white.test(., lag = 1, qstar = 2, q = 10, range = 4, 
            type = "F", scale = TRUE) %>% 
    tidy()
}

list <- list()
white <- data.frame()

set.seed(123)

for (i in names) {
  list <- white_test(main, all_of(i))
  white <- rbind(white, list)
}

white %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(p.value = round(p.value, 4)) %>% 
  mutate(`No-linealidad` = paste0(round(statistic, 2), " ", 
                             "(", format(p.value, scientific = FALSE), ")")) %>% 
  select(Variable, `No-linealidad`)
```

```{r include=FALSE}
adf_test <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    adf.test(.) %>% 
    tidy()
}

list <- list()
adf <- data.frame()

for (i in names) {
  list <- adf_test(main, all_of(i))
  adf <- rbind(adf, list)
}

adf %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(p.value = round(p.value, 4)) %>% 
  mutate(`Raíz unitaria` = paste0(round(statistic, 2), " ", 
                             "(", format(p.value, scientific = FALSE), ")")) %>% 
  select(Variable, `Raíz unitaria`)
```

```{r include=FALSE}
hurst_exp <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    hurstexp(., display = F) %>% 
    as_tibble() %>% 
    pull(1)
}

list <- list()
hurst <- data.frame()

for (i in names) {
  list <- hurst_exp(main, all_of(i))
  hurst <- rbind(hurst, list)
}

hurst %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, Hurst = X0.651292518103147) %>% 
  mutate(Hurst = round(Hurst, 4))
```

```{r include=FALSE}
table_three <- 
  autocor %>% 
  left_join(jarque) %>% 
  left_join(white) %>% 
  left_join(adf) %>% 
  left_join(hurst) %>% 
  slice(8, 14, 11, 12, 7, 13, 3, 5, 1, 6, 10, 4, 9, 2)
```

\renewcommand{\arraystretch}{1.3}

```{r table_three, echo=FALSE}
kbl(table_three, 
    booktabs = T,
    align = c("crrrrr")) %>%
  kable_styling(font_size = 9,
                full_width = T) %>% 
  row_spec(0, bold = TRUE) %>% 
  group_rows(start_row = 1, 
             end_row = 14, 
             latex_align = "c",
             latex_gap_space = "-0.5cm") %>% 
  column_spec(1, width = "2cm") %>% 
  column_spec(6, width = "1.5cm")
```

\renewcommand{\arraystretch}{1}

\vspace{-1.5mm}

\scriptsize

$^*$ Nivel de significancia entre paréntesis.

\normalsize

\vspace{3mm}

El cuadro 3 muestra un panel de pruebas estadísticas en las cuales se incluyen un *test* de Ljung--Box para autocorrelación, uno de Jarque--Bera para normalidad, una prueba de red neuronal de White para comprobar si las variables exhiben comportamientos no-lineales, una prueba de Dickey--Fuller aumentada para verificar si existen raíces unitarias y la estimación del exponente de Hurst para medir la memoria de largo plazo de las series.

Como es de esperarse, todas las variables exhiben autocorrelación y---tal y como demuestran las estadísticas descriptivas---la mayor parte de estas no se distribuyen normalmente. La prueba de White confirma que 5 de las series (las tasas de variación del índice mensual de actividad económica, del saldo de la deuda pública externa, de las exportaciones totales y del valor promedio de las exportaciones de banano, así como la tasa de interés pasiva nominal) presentan un comportamiento no-lineal.

Además, los resultados de la prueba de raíz unitaria evidencian que 4 variables (específicamente, las tasas de variación interanual de la base monetaria restringida, del medio circulante, del índice de precios al consumidor en Estados Unidos y la tasa de interés pasiva nominal) no son estacionarias. Por último, el exponente de Hurst demuestra que todas las series exhiben memoria de largo plazo.

## Validación de modelos

La validación empírica de los métodos es una preocupación constante en la literatura de *machine learning*. Tal y como observan @kuhn2022, debido a que la implementación de estos modelos conlleva una serie de pasos (estimación de parámetros, calibración de hiperparámetros, selección del modelo y evaluación de su desempeño) pero una muestra finita de observaciones, es una práctica común y recomendada dividir al conjunto de datos existente en un subconjunto de observaciones de entrenamiento (el cual es utilizado para optimizar al modelo) y un subconjunto de datos de evaluación (que se mantiene en reserva hasta que el método que tiene más probabilidades de éxito sea finalmente seleccionado).

Sin embargo, el investigador necesita entender qué tan efectivo es su modelo antes de poder emplear el conjunto de observaciones de evaluación. En este sentido, @gareth2013introduction mencionan que los métodos de remuestreo se han convertido en una herramienta esencial durante la aplicación de técnicas de aprendizaje estadístico modernas. Básicamente, estos procedimientos consisten en la extracción repetida de muestras aleatorias al conjunto de datos de entrenamiento con el fin de reajustar al modelo en cada una de ellas para obtener información adicional sobre el modelo en cuestión.

Ahora bien, cuando los datos tienen un fuerte componente temporal, los métodos usuales de remuestreo tales como validación cruzada, validación cruzada de k iteraciones, *leave-one-out cross-validation* o *bootstraping* no pueden emplearse debido a que el orden de las observaciones tiene que ser preservado, puesto que las variables se encuentran autocorrelacionadas y el modelo necesitar estimar los distintos patrones temporales que subyacen en la información: una versión más sofisticada de métodos de remuestreo es necesaria.

En este estudio, la metodología de remuestreo empleada será *rolling forecast origin resampling*. Este es un proceso en el que el conjunto de datos de entrenamiento es nuevamente dividido en dos subconjuntos de análisis/evaluación con tamaños específicos. Una primera iteración utiliza estos tamaños, comenzando desde el inicio de la serie. La segunda iteración utiliza los mismos tamaños pero se desplaza por un número determinado de muestras. Por lo que el "origen" en el que se basa el pronóstico va avanzando en el tiempo [@hyndman2018forecasting]. De esta manera, el método entrena iterativamente al modelo con datos históricos y lo evalúa con datos recientes.

## Medidas de precisión

---
bibliography: references.bib
---

# Datos y metodología

```{r include=FALSE}
pacman::p_load(tidyverse, kableExtra, here, e1071, stats, tseries, pracma, broom)
main <- read_csv(here("data", "main.csv"))
```

## Análisis de datos

Con el objeto de pronosticar la tasa de variación interanual del índice de precios al consumidor en Guatemala, la especificación de los regresores ha sido propuesta a partir de un procedimiento en el que a 36 series de tiempo---seleccionadas considerando el canal de demanda agregada, el canal de tipo de cambio y las variables del sector externo del mecanismo de transmisión de política monetaria [@castillo2014]---les son aplicadas pruebas de causalidad de Wiener-Granger respecto a la variable objetivo para cada uno de los rezagos de mediano plazo y en el que, posteriormente, son filtradas tomando en cuenta (a) la cantidad de retardos que causan en el sentido de Granger al ritmo inflacionario y (b) la magnitud en el nivel de significancia del estadístico $F$ de los *tests* previamente mencionados.

El cuadro 1 muestra a las 13 variables cuyos valores pasados son los más útiles, dado el vector inicial de posibles predictores, para pronosticar los valores futuros de la variación en el nivel de precios de la economía. Los datos corresponden al periodo que abarca de enero del 2005 a diciembre del 2021.

```{=tex}
\begin{center}

\small

\textbf{Cuadro 1:} Variables empleadas durante el proceso de predicción

\normalsize

\end{center}
```
\vspace{-3mm}

```{r include=FALSE}
table_one <- 
  tribble(
  ~ Variable, ~ Descripción, ~ Fuente,
  "ipc", "Tasa de variación interanual del índice de precios al consumidor", "SECMCA",
  "tpm", "Tasa de interés de política monetaria", "SECMCA",
  "m0", "Tasa de variación interanual de la base monetaria restringida", "SECMCA",
  "m1", "Tasa de variación interanual del medio circulante", "SECMCA",
  "imae", "Tasa de variación interanual del índice mensual de actividad económica", "SECMCA",
  "rev", "Tasa de variación interanual de los ingresos totales del gobierno central", "BANGUAT",
  "debt", "Tasa de variación interanual del saldo de la deuda pública externa", "BANGUAT",
  "exports", "Tasa de variación interanual del valor (FOB) de las exportaciones totales", "SECMCA",
  "bananas", "Tasa de variación interanual del valor promedio (dólares por tonelada) de las exportaciones de banano", "SECMCA",
  "hydro", "Tasa de variación interanual del valor promedio (dólares por barril) de las importaciones de hidrocarburos", "SECMCA",
  "lendrate", "Tasa de interés activa (real) en moneda nacional", "SECMCA",
  "deprate", "Tasa de interés pasiva (nominal) en moneda nacional", "SECMCA",
  "itcer", "Tasa de variación interanual del índice de tipo de cambio efectivo real (global)", "SECMCA",
  "cpi", "Tasa de variación interanual del índice de precios al consumidor en Estados Unidos", "FRED"
  )
```

\renewcommand{\arraystretch}{1.35}

```{r table_one, echo=FALSE}
kbl(table_one, 
    booktabs = T, 
    align = c("clc")) %>%
  kable_styling(font_size = 9,
                full_width = T) %>% 
  row_spec(0, align = "c", 
           bold = TRUE, 
           extra_css = 'vertical-align: middle !important;') %>% 
  column_spec(1, width = "1.7cm") %>% 
  column_spec(2, width = "12cm") %>% 
  group_rows(start_row = 1, 
             end_row = 14, 
             latex_align = "c",
             latex_gap_space = "-0.50cm")
```

\renewcommand{\arraystretch}{1}

```{=tex}
\begin{center}

\small

\textbf{Figura 1:} Variable objetivo y predictores seleccionados

\end{center}
```
\vspace{-12mm}

```{r include=FALSE}
order <- table_one %>% rowid_to_column(var = "id") %>% select(id, "name" = Variable)

fig1 <- 
  main %>% 
  pivot_longer(-fecha) %>% 
  arrange(name, fecha) %>% 
  left_join(order) %>% 
  mutate(name = as_factor(name)) %>% 
  group_by(name)
```

```{r fig_one, echo=FALSE, fig.align = 'center', fig.dim = c(11.5, 4.7)}
fig1 %>% 
  ggplot() +
  geom_line(aes(x = fecha, y = value, color = fct_reorder(name, id))) + 
  scale_y_continuous(limits = c(-99, 99)) +
  theme_bw() +
  theme(
        # X axis
        axis.title.x = element_blank(),
        axis.text.x = element_text(size = 12),
        # Y axis
        axis.title.y = element_blank(),
        axis.text.y = element_text(size = 12),
        # Panel
        panel.grid = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.background = element_rect(fill = "white"),
        # Legend
        legend.title = element_blank(),
        legend.text = element_text(size = 11),
        legend.position = "bottom",
        legend.justification = "center",
        legend.margin = margin(.5, 0, 0, 0, "cm")
    ) + 
    guides(colour = guide_legend(nrow = 1))
```

\vspace{-2mm}

\normalsize

El cuadro 2 presenta estadísticas descriptivas para cada una de las variables. En ellas se incluyen el primer, tercer y cuarto momentos de sus funciones de densidad de probabilidad, así como la raíz cuadrada del segundo---para evidenciar la volatilidad de las series. En este último sentido, es posible observar que las tasas de cambio interanual del valor promedio de las importaciones de hidrocarburos, las exportaciones totales y los ingresos del gobierno central son los predictores que exhiben la mayor volatilidad durante el periodo del análisis.

Las estadísticas descriptivas también demuestran que esta investigación lidia mayoritariamente con variables que no se distribuyen normalmente, de las cuales 9 presentan distribuciones leptocúrticas, 2 platicúrticas y 3 una distribución aproximadamente normal, en términos de exceso de curtosis. Además, el estadístico de asimetría comprueba que 4 series se encuentran sesgadas hacia la izquierda y el resto de ellas hacia la derecha (exceptuando a la tasa de variación de los ingresos del gobierno central, cuya asimetría es cercana a 0).

```{=tex}
\begin{center}

\small

\textbf{Cuadro 2:} Estadísticas descriptivas

\normalsize

\end{center}
```
\vspace{-4mm}

```{r include=FALSE}
main_longer <- 
  main %>% 
  pivot_longer(-fecha, names_to = "Variable", values_to = "value") %>% 
  arrange(Variable, fecha) %>% 
  group_by(Variable)

sumtable <- 
  main_longer %>% 
  summarise(Media = round(mean(value), 2),
            Mediana = round(median(value), 2),
            Mínimo = round(min(value), 2),
            Máximo = round(max(value), 2),
            `Desv. Est.` = round(sd(value), 2),
            Asimetría = round(skewness(value), 2),
            Curtosis = round(kurtosis(value), 2))

obs <- 
  main_longer %>% 
  count(Variable) %>% 
  rename(`Obs.` = n)

table_two <- 
  sumtable %>% 
  left_join(obs) %>% 
  slice(8, 14, 11, 12, 7, 13, 3, 5, 1, 6, 10, 4, 9, 2) %>% 
  as.data.frame()
```

\renewcommand{\arraystretch}{1.2}

```{r table_two, echo=FALSE}
kbl(table_two, 
    booktabs = T,
    align = c("c")) %>%
  kable_styling(font_size = 9,
                full_width = T) %>% 
  row_spec(0, bold = TRUE) %>% 
  column_spec(1, width = "1.5cm") %>% 
  column_spec(6, width = "1.8cm") %>% 
  column_spec(9, width = "1cm") %>% 
  group_rows(start_row = 1, 
             end_row = 14, 
             latex_align = "c",
             latex_gap_space = "-0.35cm")
```

\renewcommand{\arraystretch}{1}

```{=tex}
\begin{center}

\small

\textbf{Cuadro 3:} Pruebas estadísticas

\normalsize

\end{center}
```
\vspace{-2.7mm}

```{r include=FALSE}
names <- main_longer %>% distinct(Variable) %>% pull()
```

```{r include=FALSE}
autocorrelation <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    Box.test(., lag = 12, type = "Ljung-Box") %>% 
    tidy()
}

list <- list()
autocor <- data.frame()

for (i in names) {
  list <- autocorrelation(main, all_of(i))
  autocor <- rbind(autocor, list)
}

autocor %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(Autocorrelación = paste(round(statistic, 2), "(0.0000)", sep = " ")) %>% 
  select(Variable, Autocorrelación)
```

```{r include=FALSE}
jarque_bera <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    jarque.bera.test(.) %>% 
    tidy()
}

list <- list()
jarque <- data.frame()

for (i in names) {
  list <- jarque_bera(main, all_of(i))
  jarque <- rbind(jarque, list)
}

jarque %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(p.value = round(p.value, 4)) %>% 
  mutate(Normalidad = paste0(round(statistic, 2), " ", 
                             "(", format(p.value, scientific = FALSE), ")")) %>% 
  select(Variable, Normalidad)
```

```{r include=FALSE}
white_test <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    white.test(., lag = 1, qstar = 2, q = 10, range = 4, 
            type = "F", scale = TRUE) %>% 
    tidy()
}

list <- list()
white <- data.frame()

set.seed(123)

for (i in names) {
  list <- white_test(main, all_of(i))
  white <- rbind(white, list)
}

white %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(p.value = round(p.value, 4)) %>% 
  mutate(`No-linealidad` = paste0(round(statistic, 2), " ", 
                             "(", format(p.value, scientific = FALSE), ")")) %>% 
  select(Variable, `No-linealidad`)
```

```{r include=FALSE}
adf_test <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    adf.test(.) %>% 
    tidy()
}

list <- list()
adf <- data.frame()

for (i in names) {
  list <- adf_test(main, all_of(i))
  adf <- rbind(adf, list)
}

adf %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, statistic, p.value) %>% 
  mutate(p.value = round(p.value, 4)) %>% 
  mutate(`Raíz unitaria` = paste0(round(statistic, 2), " ", 
                             "(", format(p.value, scientific = FALSE), ")")) %>% 
  select(Variable, `Raíz unitaria`)
```

```{r include=FALSE}
hurst_exp <- function(data, variable) {
  data %>% 
    select(!!enquo(variable)) %>% 
    pull() %>% 
    as.ts() %>% 
    hurstexp(., display = F) %>% 
    as_tibble() %>% 
    pull(1)
}

list <- list()
hurst <- data.frame()

for (i in names) {
  list <- hurst_exp(main, all_of(i))
  hurst <- rbind(hurst, list)
}

hurst %<>% 
  cbind(main_longer %>% distinct(Variable)) %>% 
  select(Variable, Hurst = X0.651292518103147) %>% 
  mutate(Hurst = round(Hurst, 4))
```

```{r include=FALSE}
table_three <- 
  autocor %>% 
  left_join(jarque) %>% 
  left_join(white) %>% 
  left_join(adf) %>% 
  left_join(hurst) %>% 
  slice(8, 14, 11, 12, 7, 13, 3, 5, 1, 6, 10, 4, 9, 2)
```

\renewcommand{\arraystretch}{1.3}

```{r table_three, echo=FALSE}
kbl(table_three, 
    booktabs = T,
    align = c("crrrrr")) %>%
  kable_styling(font_size = 9,
                full_width = T) %>% 
  row_spec(0, bold = TRUE) %>% 
  group_rows(start_row = 1, 
             end_row = 14, 
             latex_align = "c",
             latex_gap_space = "-0.5cm") %>% 
  column_spec(1, width = "2cm") %>% 
  column_spec(6, width = "1.5cm")
```

\renewcommand{\arraystretch}{1}

\vspace{-1.6mm}

\scriptsize

$^*$ Nivel de significancia entre paréntesis.

\normalsize

\vspace{3mm}

El cuadro 3 muestra un panel de pruebas estadísticas compuesto por un *test* de Ljung--Box para autocorrelación, uno de Jarque--Bera para normalidad, una prueba de red neuronal de White para comprobar si las variables exhiben comportamientos no-lineales, una prueba de Dickey--Fuller aumentada para verificar si existen raíces unitarias y la estimación del exponente de Hurst para medir la memoria de largo plazo de las series.

Como es de esperar, todas las variables exhiben correlación serial y---tal como demuestra el cuadro de estadísticas descriptivas---la mayor parte de estas no se distribuyen normalmente. La prueba de White confirma que 5 de las series (la tasa de interés pasiva nominal y las tasas de variación del índice mensual de actividad económica, del saldo de la deuda pública externa, de las exportaciones totales y del valor promedio de las exportaciones de banano) presentan un comportamiento no-lineal.

Además, los resultados de la prueba de raíz unitaria evidencian que la tasa de interés pasiva nominal y las tasas de cambio interanual de la base monetaria restringida, del medio circulante y del índice de precios al consumidor en Estados Unidos no son estacionarias. Por último, el exponente de Hurst demuestra que todas las series exhiben memoria de largo plazo.

## Métodos empíricos

### Modelos estadísticos

### Modelos de aprendizaje de máquina

## Validación de modelos

La validación empírica de los modelos es una preocupación constante en la literatura de *machine learning*. Tal y como observan @kuhn2022, debido a que la implementación de estos métodos conlleva una serie de pasos (estimación de parámetros, calibración de hiperparámetros, selección del modelo, evaluación de su desempeño) y, al mismo tiempo, una muestra finita de observaciones, es una práctica común y recomendada dividir al conjunto de datos existente en un subconjunto de observaciones de entrenamiento (el cual es utilizado para optimizar al modelo) y un subconjunto de datos de evaluación (que se mantiene en reserva hasta que el método que tiene más probabilidades de éxito sea finalmente escogido).

Sin embargo, el investigador necesita entender qué tan efectivo es su modelo antes de poder emplear el conjunto de observaciones de evaluación. En este sentido, @gareth2013introduction mencionan que los métodos de remuestreo se han convertido en una herramienta esencial durante la aplicación de técnicas modernas de aprendizaje estadístico. Básicamente, estos procedimientos consisten en la extracción repetida de muestras aleatorias al conjunto de datos de entrenamiento con el fin de reajustar al modelo en cada una de ellas para obtener información adicional sobre el modelo en cuestión.

Ahora bien, cuando los datos tienen un fuerte componente temporal, los métodos usuales de remuestreo tales como validación cruzada y *bootstraping* no pueden emplearse debido a que el orden de las observaciones tiene que ser preservado---ya que las series se encuentran naturalmente autocorrelacionadas---y el modelo necesita aprender los distintos patrones cíclicos y tendenciales que subyacen en la información: una versión más sofisticada de métodos de remuestreo es necesaria.

En este estudio la metodología de remuestreo empleada será *rolling forecast origin resampling*, un procedimiento en el que el conjunto de datos de entrenamiento es nuevamente dividido en dos subconjuntos de análisis/evaluación con tamaños específicos. Una primera iteración utiliza estos tamaños, comenzando desde el inicio de la serie. La segunda iteración utiliza los mismos tamaños pero se desplaza por un número determinado de muestras. El proceso continúa hasta que el conjunto de datos de entrenamiento es agotado por completo, por lo que el origen en el que se basan los pronósticos va avanzando en el tiempo [@hyndman2018forecasting]. Así, el método entrena iterativamente al modelo con datos históricos, lo evalúa con datos cada vez más recientes y la precisión en el pronóstico es calculada promediando los resultados de una función de pérdida en los subconjuntos de evaluación.

## Procedimiento de pronóstico

Aunque la estimación de los valores futuros de una serie puede ser llevada a cabo de diversas maneras---por ejemplo, @taieb2011 hacen un análisis teórico-comparativo de cinco estrategias que pueden ser utilizadas para generar pronósticos de varios pasos hacia adelante (*multi-step ahead*)---existen dos métodos particulares que sobresalen en la literatura.

El primero y el más antiguo de ellos es el método iterativo (también llamado recursivo o *multi-stage*). Con esta estrategia, un modelo $f$ es entrenado para pronosticar un único periodo hacia adelante. Subsecuentemente, un segundo pronóstico $h+2$ es obtenido utilizando la predicción $h +1$ producida por el modelo y el proceso se repite hasta llegar al final del horizonte de pronóstico $H$ [@hamzaçebi2009].

Mientras tanto, el segundo procedimiento es llamado método directo y consiste en pronosticar cada periodo $h$ de manera independiente al resto de los periodos que conforman al horizonte de pronóstico $H$. De tal manera, $H$ modelos $f_h$ son producidos para predecir los valores futuros de la serie de tiempo $[y_1, ..., y_N]$ [@taieb2011].

Ambas estrategias cuentan con ventajas y desventajas. Dependiendo de las características de la serie, el método recursivo puede tener un peor desempeño dado a que dicha estrategia es sensible a la acumulación de errores durante la iteración de los pronósticos, propagándolos hacia adelante y teniendo un efecto negativo sobre el resto de las predicciones $h+i$. Por otro lado, el procedimiento directo induce independencia condicional a lo largo de las predicciones individuales del horizonte $H$, aspecto que afecta a la precisión de los pronósticos al impedir que el modelo tome en cuenta la complejidad entre las relaciones de la variable objetivo y el resto de sus predictores [@taieb2011].

Tal y como mencionan @marcellino2006, la cuestión sobre cuál procedimiento elegir es más bien una pregunta empírica. Por lo general, la literatura se mantiene dividida entre estudios que encuentran que uno de estos métodos supera en términos de eficiencia de pronóstico al otro. Esta investigación optará por utilizar el método recursivo durante el procedimiento de predicción de los métodos econométricos (en línea con la metodología Box-Jenkins) y la estrategia directa para los modelos de aprendizaje estadístico.

## Medidas de precisión

Elegir medidas de precisión para comparar distintos métodos de pronóstico no es necesariamente una tarea sencilla. En primer lugar, existe una amplia gama de medidas que pueden ser catalogadas en siete grupos distintos [@shcherbakov2013]. En segundo, es importante considerar que la clasificación relativa del resultado de los diversos métodos que se evalúan puede variar según la medida que se utilice [@makridakis2000]. Además, cada medida tiene desventajas que pueden conducir a una evaluación inexacta de los resultados, por lo que---así como @mathews1994 señalan---ninguna medida por sí sola brinda una pauta inequívoca de la eficiencia en las predicciones.

Con el fin de evaluar las diferencias en la precisión de los pronósticos entre métodos tradicionales y de aprendizaje estadístico, este estudio utilizará 3 medidas distintas. La primera de ellas, el error absoluto medio (MAE), es seleccionada no solo por ser una opción ampliamente utilizada al comparar distintos métodos que predicen un solo conjunto de datos, sino por contar con la ventaja de presentar una mayor robustez a valores atípicos que otras medidas dependientes de escala como la raíz del error cuadrático medio (RMSE) [@shcherbakov2013]. Esta medida se define como,

$$
MAE = \frac{1}{n}\sum_{i=1}^{n}|y_{t}-\hat{y}_{t}|.
$$

La segunda medida a considerar será el error absoluto medio relativo (rMAE), que es calculado como el ratio entre el MAE del método $i$ que se desea evaluar y el $MAE_{rw}$ de un método utilizado como punto de referencia, que en el caso de la presente investigación será un modelo de caminata aleatoria. @hyndman2006 observan que una de las ventajas de esta medida es su interpretabilidad: Un $rMAE > 1$ significa que el método propuesto se desempeña peor que lo que lo hace el modelo de referencia, mientras que un $rMAE < 1$ denota lo opuesto. Formalmente,

$$rMAE = \frac{MAE_i}{MAE_{rw}}.
$$

La última medida que será empleada en la presente investigación es el error medio absoluto escalado (MASE), un método propuesto por primera vez en @hyndman2006 con el objeto de brindar una mejor opción que el error porcentual absoluto medio simétrico (sMAPE). Dicha medida se encuentra definida de la siguiente manera:

$$MASE=\frac{1}{k}\frac{\sum_{t=1}^{k}|y_{t}-\hat{y}_{t}|}{\frac{1}{n-m}\sum_{t=1}^{k}|y_{t}-\hat{y}_{t-m}|},
$$

donde $n$ es el número de observaciones históricas disponibles y $m$ es la frecuencia de la serie de tiempo. Cabe resaltar que su interpretación es similar a la interpretación del rMAE: un $MASE < 1$ indica que los pronósticos del modelo evaluado son, en promedio, más exactos que los pronósticos del modelo de referencia [@makridakis2018].

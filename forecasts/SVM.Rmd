# Polynomial support vector machines

```{r}
pacman::p_load(tidyverse, tidymodels, timetk, here, kernlab, tictoc, vip)
data <- read_csv(here("data", "main.csv")) %>% rename("date" = fecha)
```

## (a) Forecast function

```{r}
svm <-
  function(assess) {
    tic("SVM")
    
    # Training and testing partitions
    splits <- data %>% time_series_split(date, assess = assess, cumulative = TRUE)
    train <- training(splits)
    
    # Model specification
    svm <-
      svm_poly(cost = tune(),
               degree = tune(),
               scale_factor = tune()) %>%
      set_engine("kernlab") %>%
      set_mode("regression")
    
    # Feature engineering
    recipe <- train %>% recipe(ipc ~ .) %>% step_rm(date)
    
    # Workflow
    workflow <- workflow() %>% add_model(svm) %>% add_recipe(recipe)
    
    # Hyperparameter tuning
    resamples <-
      train %>%
      rolling_origin(
        initial = (8 * 12),
        assess = (2 * 12),
        skip = 10,
        cumulative = TRUE
      )
    
    grid <-
      grid_latin_hypercube(
        cost(),
        degree(),
        scale_factor(),
        size = 100)
    
    metrics <- metric_set(mae, mase)
    
    doParallel::registerDoParallel()
    
    set.seed(123)
    tune <- 
      tune_grid(
        workflow,
        resamples = resamples,
        grid = grid,
        metrics = metrics,
        control = control_grid(save_pred = TRUE)
      )
    
    best_mae <- select_best(tune, "mae")
    
    # Final workflow
    final_workflow <-
      finalize_workflow(workflow,
                        best_mae)
    
    # Final model
    model <- last_fit(final_workflow, splits, metrics = metrics)
    metrics <- collect_metrics(model)
    
    # Forecast
    forecast <- model %>% collect_predictions() %>% select(.pred, .row, ipc)
    
    # Time elapsed
    toc(log = TRUE)
    time <- tic.log(format = TRUE)
    tic.clearlog()
    
    # Collect results
    results <- list(forecast, metrics, time)
    return(results)
  }
```

```{r}
svm_3 <- svm("3 months")

svm_3[[1]] %>% write_csv(here("results", "svm_3_forecast.csv"))
svm_3[[2]] %>% write_csv(here("results", "svm_3_metrics.csv"))
svm_3[[3]][[1]] %>% as_tibble() %>% write_csv(here("results", "svm_3_time.csv"))
```

```{r}
svm_9 <- svm("9 months")

svm_9[[1]] %>% write_csv(here("results", "svm_9_forecast.csv"))
svm_9[[2]] %>% write_csv(here("results", "svm_9_metrics.csv"))
svm_9[[3]][[1]] %>% as_tibble() %>% write_csv(here("results", "svm_9_time.csv"))
```

```{r}
svm_12 <- svm("12 months")

svm_12[[1]] %>% write_csv(here("results", "svm_12_forecast.csv"))
svm_12[[2]] %>% write_csv(here("results", "svm_12_metrics.csv"))
svm_12[[3]][[1]] %>% as_tibble() %>% write_csv(here("results", "svm_12_time.csv"))
```

```{r}
svm_24 <- svm("24 months")

svm_24[[1]] %>% write_csv(here("results", "svm_24_forecast.csv"))
svm_24[[2]] %>% write_csv(here("results", "svm_24_metrics.csv"))
svm_24[[3]][[1]] %>% as_tibble() %>% write_csv(here("results", "svm_24_time.csv"))
```

### Safety checks

```{r}
svm_24[[1]] %>% 
  pivot_longer(-.row) %>% 
  ggplot(aes(.row, value, color = name)) +
  geom_line()
```

## (b) Model building

### Train and test sets

```{r}
splits <- data %>% time_series_split(date, assess = "24 months", cumulative = TRUE)
train <- training(splits)
```

### Model specification

```{r}
svm <-
  svm_poly(cost = tune(),
          degree = tune(),
          scale_factor = tune()) %>%
  set_engine("kernlab") %>% 
  set_mode("regression")
```

### Feature engineering

```{r}
recipe <- 
  train %>% 
  recipe(ipc ~ .) %>% 
  step_rm(date)
```

```{r}
recipe %>% prep() %>% juice()
```

### Workflow

```{r}
workflow <- 
  workflow() %>% 
  add_model(svm) %>% 
  add_recipe(recipe)
```

### Hyperparameter tuning

```{r}
resamples <- 
  train %>% 
  rolling_origin(
    initial = 8 * 12,
    assess = 2 * 12,
    skip = 10,
    cumulative = TRUE)
```

```{r}
resamples %>%
  tk_time_series_cv_plan() %>%
  plot_time_series_cv_plan(date, ipc, 
                           .facet_ncol = 2, .interactive = F)
```

```{r}
grid <- 
  grid_latin_hypercube(
    cost(),
    degree(),
    scale_factor(),
    size = 15
)
```

```{r}
doParallel::registerDoParallel()

metrics <- metric_set(mae, mase)

tic("SVM")

set.seed(123)
tune <- tune_grid(
  workflow,
  resamples = resamples,
  grid = grid,
  metrics = metrics,
  control = control_grid(save_pred = TRUE)
)

toc(log = TRUE)
time <- tic.log(format = TRUE)
tic.clearlog()
```

```{r}
tune %>% collect_metrics() %>% print(n = Inf)
best_mae <- select_best(tune, "mae"); best_mae
```

```{r}
tune %>%
  collect_metrics() %>%
  filter(.metric == "mae") %>%
  select(mean, cost:scale_factor) %>%
  pivot_longer(cost:scale_factor,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "MAE")
```

### Final model

```{r}
final <- 
  finalize_workflow(
  workflow,
  best_mae
)
```

```{r}
final %>%
  fit(data = train) %>%
  extract_fit_parsnip() %>%
  vip(geom = "col")
```

```{r}
final_res <- last_fit(final, splits, metrics = metrics)
collect_metrics(final_res)
```

### Forecast

```{r}
final_res %>%
  collect_predictions() %>% 
  select(.pred, .row, ipc) %>% 
  pivot_longer(-.row) %>% 
  ggplot(aes(.row, value, color = name)) +
  geom_line()
```
